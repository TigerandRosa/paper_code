#!/usr/bin/env python3
# -*- coding:utf-8 -*-
# Copyright (c) Megvii, Inc. and its affiliates.

import torch
import torch.nn as nn
from torch.nn import functional as F
from .darknet import BaseConv, CSPDarknet, CSPLayer, DWConv, CSPLayer_neck, simam_module, Conv_GS, VoVGSCSP_ECA, GhostConv
from torch.nn.modules.conv import _ConvNd
from torch.nn.modules.utils import _pair
import math


class FReLU(nn.Module):
    """
    FReLU https://arxiv.org/abs/2007.11824
    """
    def __init__(self, c1, k=3):  # ch_in, kernel
        super().__init__()
        # 定义漏斗条件T(x)  参数池窗口（Parametric Pooling Window ）来创建空间依赖
        # nn.Con2d(in_channels, out_channels, kernel_size, stride, padding, dilation=1, bias=True)
        # 使用 深度可分离卷积 DepthWise Separable Conv + BN 实现T(x)
        self.conv = nn.Conv2d(c1, c1, k, 1, 1, groups=c1, bias=False)
        self.bn = nn.BatchNorm2d(c1)

    def forward(self, x):
        # f(x)=max(x, T(x))
        return torch.max(x, self.bn(self.conv(x)))


class MetaAconC(nn.Module):
    r""" ACON activation (activate or not).
    MetaAconC: (p1*x-p2*x) * sigmoid(beta*(p1*x-p2*x)) + p2*x, beta is generated by a small network
    according to "Activate or Not: Learning Customized Activation" <https://arxiv.org/pdf/2009.04759.pdf>.
    """

    def __init__(self, c1, k=1, s=1, r=16):  # ch_in, kernel, stride, r
        super().__init__()
        # 为了减少参数我们在两个中间的channel加了个缩放参数r，默认设置为16
        c2 = max(r, c1 // r)
        self.p1 = nn.Parameter(torch.randn(1, c1, 1, 1))
        self.p2 = nn.Parameter(torch.randn(1, c1, 1, 1))
        self.fc1 = nn.Conv2d(c1, c2, k, s, bias=True)
        self.fc2 = nn.Conv2d(c2, c1, k, s, bias=True)
        # self.bn1 = nn.BatchNorm2d(c2)
        # self.bn2 = nn.BatchNorm2d(c1)

    def forward(self, x):
        # 自适应函数的设计空间包含了layer-wise, channel-wise, pixel-wise这三种空间 分别对应的是层, 通道, 像素
        # 这里我们选择了channel-wise 首先分别对H, W维度求均值 然后通过两个卷积层 使得每一个通道所有像素共享一个权重
        # 最后由sigmoid激活函数求得beta
        y = x.mean(dim=2, keepdims=True).mean(dim=3, keepdims=True)
        # batch-size 1 bug/instabilities https://github.com/ultralytics/yolov5/issues/2891
        # beta = torch.sigmoid(self.bn2(self.fc2(self.bn1(self.fc1(y)))))  # bug/unstable
        beta = torch.sigmoid(self.fc2(self.fc1(y)))  # bug patch BN layers removed
        dpx = (self.p1 - self.p2) * x
        return dpx * torch.sigmoid(beta * dpx) + self.p2 * x


# CBS-CBF
class BaseConv_frelu(nn.Module):
    def __init__(self, in_channels, out_channels, ksize, stride, groups=1, bias=False):
        super().__init__()
        pad         = (ksize - 1) // 2
        self.conv   = nn.Conv2d(in_channels, out_channels, kernel_size=ksize, stride=stride, padding=pad, groups=groups, bias=bias)
        self.bn     = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.03)
        self.act    = FReLU(out_channels)

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def fuseforward(self, x):
        return self.act(self.conv(x))


class BaseConv_acon(nn.Module):
    def __init__(self, in_channels, out_channels, ksize, stride, groups=1, bias=False):
        super().__init__()
        pad         = (ksize - 1) // 2
        self.conv   = nn.Conv2d(in_channels, out_channels, kernel_size=ksize, stride=stride, padding=pad, groups=groups, bias=bias)
        self.bn     = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.03)
        self.act    = MetaAconC(out_channels)

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def fuseforward(self, x):
        return self.act(self.conv(x))


class AddCoords(nn.Module):

    def __init__(self, with_r=False):
        super().__init__()
        self.with_r = with_r

    def forward(self, input_tensor):
        """
        Args:
            input_tensor: shape(batch, channel, x_dim, y_dim)
        """
        batch_size, _, x_dim, y_dim = input_tensor.size()

        xx_channel = torch.arange(x_dim).repeat(1, y_dim, 1)
        yy_channel = torch.arange(y_dim).repeat(1, x_dim, 1).transpose(1, 2)

        xx_channel = xx_channel.float() / (x_dim - 1)
        yy_channel = yy_channel.float() / (y_dim - 1)

        xx_channel = xx_channel * 2 - 1
        yy_channel = yy_channel * 2 - 1

        xx_channel = xx_channel.repeat(batch_size, 1, 1, 1).transpose(2, 3)
        yy_channel = yy_channel.repeat(batch_size, 1, 1, 1).transpose(2, 3)

        ret = torch.cat([
            input_tensor,
            xx_channel.type_as(input_tensor),
            yy_channel.type_as(input_tensor)], dim=1)

        if self.with_r:
            rr = torch.sqrt(torch.pow(xx_channel.type_as(input_tensor) - 0.5, 2) + torch.pow(yy_channel.type_as(input_tensor) - 0.5, 2))
            ret = torch.cat([ret, rr], dim=1)

        return ret


class CoordConv(nn.Module):

    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, with_r=False):
        super().__init__()
        self.addcoords = AddCoords(with_r=with_r)
        in_channels += 2
        if with_r:
            in_channels += 1
        self.conv = BaseConv(in_channels, out_channels, ksize=kernel_size, stride=stride)

    def forward(self, x):
        x = self.addcoords(x)
        x = self.conv(x)
        return x


# class DSConv(_ConvNd):
#     def __init__(self, in_channels, out_channels, kernel_size, stride=1,
#                  padding=None, dilation=1, groups=1, padding_mode='zeros', bias=False, block_size=32, KDSBias=False, CDS=False):
#         padding = _pair(autopad(kernel_size, padding))
#         kernel_size = _pair(kernel_size)
#         stride = _pair(stride)
#         dilation = _pair(dilation)
#
#         blck_numb = math.ceil(((in_channels)/(block_size*groups)))
#         super(DSConv, self).__init__(
#             in_channels, out_channels, kernel_size, stride, padding, dilation,
#             False, _pair(0), groups, bias, padding_mode)
#
#         # KDS weight From Paper
#         self.intweight = torch.Tensor(out_channels, in_channels, *kernel_size)
#         self.alpha = torch.Tensor(out_channels, blck_numb, *kernel_size)
#
#         # KDS bias From Paper
#         self.KDSBias = KDSBias
#         self.CDS = CDS
#
#         if KDSBias:
#             self.KDSb = torch.Tensor(out_channels, blck_numb, *kernel_size)
#         if CDS:
#             self.CDSw = torch.Tensor(out_channels)
#             self.CDSb = torch.Tensor(out_channels)
#
#         self.reset_parameters()
#
#     def get_weight_res(self):
#         # Include expansion of alpha and multiplication with weights to include in the convolution layer here
#         alpha_res = torch.zeros(self.weight.shape).to(self.alpha.device)
#
#         # Include KDSBias
#         if self.KDSBias:
#             KDSBias_res = torch.zeros(self.weight.shape).to(self.alpha.device)
#
#         # Handy definitions:
#         nmb_blocks = self.alpha.shape[1]
#         total_depth = self.weight.shape[1]
#         bs = total_depth//nmb_blocks
#
#         llb = total_depth-(nmb_blocks-1)*bs
#
#         # Casting the Alpha values as same tensor shape as weight
#         for i in range(nmb_blocks):
#             length_blk = llb if i==nmb_blocks-1 else bs
#
#             shp = self.alpha.shape # Notice this is the same shape for the bias as well
#             to_repeat=self.alpha[:, i, ...].view(shp[0],1,shp[2],shp[3]).clone()
#             repeated = to_repeat.expand(shp[0], length_blk, shp[2], shp[3]).clone()
#             alpha_res[:, i*bs:(i*bs+length_blk), ...] = repeated.clone()
#
#             if self.KDSBias:
#                 to_repeat = self.KDSb[:, i, ...].view(shp[0], 1, shp[2], shp[3]).clone()
#                 repeated = to_repeat.expand(shp[0], length_blk, shp[2], shp[3]).clone()
#                 KDSBias_res[:, i*bs:(i*bs+length_blk), ...] = repeated.clone()
#
#         if self.CDS:
#             to_repeat = self.CDSw.view(-1, 1, 1, 1)
#             repeated = to_repeat.expand_as(self.weight)
#             print(repeated.shape)
#
#         # Element-wise multiplication of alpha and weight
#         weight_res = torch.mul(alpha_res, self.weight)
#         if self.KDSBias:
#             weight_res = torch.add(weight_res, KDSBias_res)
#         return weight_res
#
#     def forward(self, input):
#         # Get resulting weight
#         #weight_res = self.get_weight_res()
#
#         # Returning convolution
#         return F.conv2d(input, self.weight, self.bias,
#                             self.stride, self.padding, self.dilation,
#                             self.groups)



# class YOLOXHead(nn.Module):
#     def __init__(self, num_classes, width = 1.0, in_channels = [256, 512, 1024], depthwise = False, act="silu"):
#         super().__init__()
#         Conv            = DWConv if depthwise else BaseConv
#
#         self.cls_convs  = nn.ModuleList()
#         self.reg_convs  = nn.ModuleList()
#         self.cls_preds  = nn.ModuleList()
#         self.reg_preds  = nn.ModuleList()
#         self.obj_preds  = nn.ModuleList()
#         self.stems      = nn.ModuleList()
#
#         for i in range(len(in_channels)):
#             self.stems.append(BaseConv(in_channels =int(in_channels[i] * width), out_channels = int(256 * width), ksize = 1, stride = 1, act=act))
#             self.cls_convs.append(nn.Sequential(*[
#                 BaseConv(in_channels = int(256 * width), out_channels = int(256 * width), ksize = 3, stride = 1, act=act),
#                 GhostConv(int(256 * width), int(256 * width)),
#                 # SAConv2d(in_channels=int(256 * width), out_channels=int(256 * width), kernel_size=3),
#                 # SAConv2d(in_channels=int(256 * width), out_channels=int(256 * width), kernel_size=3),
#             ]))
#             self.cls_preds.append(
#                 nn.Conv2d(in_channels = int(256 * width), out_channels = num_classes, kernel_size = 1, stride = 1, padding = 0)
#                 # CoordConv(in_channels=int(256 * width), out_channels=num_classes)
#             )
#             self.reg_convs.append(nn.Sequential(*[
#                 BaseConv(in_channels = int(256 * width), out_channels = int(256 * width), ksize = 3, stride = 1, act=act),
#                 GhostConv( int(256 * width),  int(256 * width)),
#                 # SAConv2d(in_channels=int(256 * width), out_channels=int(256 * width), kernel_size=3),
#                 # SAConv2d(in_channels=int(256 * width), out_channels=int(256 * width), kernel_size=3),
#             ]))
#             self.reg_preds.append(
#                 nn.Conv2d(in_channels = int(256 * width), out_channels = 4, kernel_size = 1, stride = 1, padding = 0)
#                 # CoordConv(in_channels=int(256 * width), out_channels=4)
#             )
#             self.obj_preds.append(
#                 nn.Conv2d(in_channels = int(256 * width), out_channels = 1, kernel_size = 1, stride = 1, padding = 0)
#                 # CoordConv(in_channels=int(256 * width), out_channels=1)
#             )
#
#     def forward(self, inputs):
#         #---------------------------------------------------#
#         #   inputs输入
#         #   P3_out  80, 80, 256
#         #   P4_out  40, 40, 512
#         #   P5_out  20, 20, 1024
#         #---------------------------------------------------#
#         outputs = []
#         for k, x in enumerate(inputs):
#             #---------------------------------------------------#
#             #   利用1x1卷积进行通道整合
#             #---------------------------------------------------#
#             x       = self.stems[k](x)
#             #---------------------------------------------------#
#             #   利用两个卷积标准化激活函数来进行特征提取
#             #---------------------------------------------------#
#             cls_feat    = self.cls_convs[k](x)
#             #---------------------------------------------------#
#             #   判断特征点所属的种类
#             #   80, 80, num_classes
#             #   40, 40, num_classes
#             #   20, 20, num_classes
#             #---------------------------------------------------#
#             cls_output  = self.cls_preds[k](cls_feat)
#
#             #---------------------------------------------------#
#             #   利用两个卷积标准化激活函数来进行特征提取
#             #---------------------------------------------------#
#             reg_feat    = self.reg_convs[k](x)
#             #---------------------------------------------------#
#             #   特征点的回归系数
#             #   reg_pred 80, 80, 4
#             #   reg_pred 40, 40, 4
#             #   reg_pred 20, 20, 4
#             #---------------------------------------------------#
#             reg_output  = self.reg_preds[k](reg_feat)
#             #---------------------------------------------------#
#             #   判断特征点是否有对应的物体
#             #   obj_pred 80, 80, 1
#             #   obj_pred 40, 40, 1
#             #   obj_pred 20, 20, 1
#             #---------------------------------------------------#
#             obj_output  = self.obj_preds[k](reg_feat)
#
#             output      = torch.cat([reg_output, obj_output, cls_output], 1)
#             outputs.append(output)
#         return outputs


class YOLOXHead(nn.Module):
    def __init__(self, num_classes, width = 1.0, in_channels = [256, 512, 1024], depthwise = False, act="silu"):
        super().__init__()
        Conv            = DWConv if depthwise else BaseConv

        self.cls_convs  = nn.ModuleList()
        self.reg_convs  = nn.ModuleList()
        self.cls_preds  = nn.ModuleList()
        self.reg_preds  = nn.ModuleList()
        self.obj_preds  = nn.ModuleList()
        self.stems      = nn.ModuleList()

        for i in range(len(in_channels)):
            self.stems.append(BaseConv(in_channels =int(in_channels[i] * width), out_channels = int(256 * width), ksize = 1, stride = 1, act=act))
            self.cls_convs.append(nn.Sequential(*[
                BaseConv(in_channels = int(256 * width), out_channels = int(256 * width), ksize = 3, stride = 1, act=act),
                BaseConv(in_channels = int(256 * width), out_channels = int(256 * width), ksize = 3, stride = 1, act=act),
                # SAConv2d(in_channels=int(256 * width), out_channels=int(256 * width), kernel_size=3),
                # SAConv2d(in_channels=int(256 * width), out_channels=int(256 * width), kernel_size=3),
            ]))
            self.cls_preds.append(
                nn.Conv2d(in_channels = int(256 * width), out_channels = num_classes, kernel_size = 1, stride = 1, padding = 0)
                # CoordConv(in_channels=int(256 * width), out_channels=num_classes)
            )
            self.reg_convs.append(nn.Sequential(*[
                BaseConv(in_channels = int(256 * width), out_channels = int(256 * width), ksize = 3, stride = 1, act=act),
                BaseConv(in_channels = int(256 * width), out_channels = int(256 * width), ksize = 3, stride = 1, act=act),
                # SAConv2d(in_channels=int(256 * width), out_channels=int(256 * width), kernel_size=3),
                # SAConv2d(in_channels=int(256 * width), out_channels=int(256 * width), kernel_size=3),
            ]))
            self.reg_preds.append(
                nn.Conv2d(in_channels = int(256 * width), out_channels = 4, kernel_size = 1, stride = 1, padding = 0)
                # CoordConv(in_channels=int(256 * width), out_channels=4)
            )
            self.obj_preds.append(
                nn.Conv2d(in_channels = int(256 * width), out_channels = 1, kernel_size = 1, stride = 1, padding = 0)
                # CoordConv(in_channels=int(256 * width), out_channels=1)
            )

    def forward(self, inputs):
        #---------------------------------------------------#
        #   inputs输入
        #   P3_out  80, 80, 256
        #   P4_out  40, 40, 512
        #   P5_out  20, 20, 1024
        #---------------------------------------------------#
        outputs = []
        for k, x in enumerate(inputs):
            #---------------------------------------------------#
            #   利用1x1卷积进行通道整合
            #---------------------------------------------------#
            x       = self.stems[k](x)
            #---------------------------------------------------#
            #   利用两个卷积标准化激活函数来进行特征提取
            #---------------------------------------------------#
            cls_feat    = self.cls_convs[k](x)
            #---------------------------------------------------#
            #   判断特征点所属的种类
            #   80, 80, num_classes
            #   40, 40, num_classes
            #   20, 20, num_classes
            #---------------------------------------------------#
            cls_output  = self.cls_preds[k](cls_feat)

            #---------------------------------------------------#
            #   利用两个卷积标准化激活函数来进行特征提取
            #---------------------------------------------------#
            reg_feat    = self.reg_convs[k](x)
            #---------------------------------------------------#
            #   特征点的回归系数
            #   reg_pred 80, 80, 4
            #   reg_pred 40, 40, 4
            #   reg_pred 20, 20, 4
            #---------------------------------------------------#
            reg_output  = self.reg_preds[k](reg_feat)
            #---------------------------------------------------#
            #   判断特征点是否有对应的物体
            #   obj_pred 80, 80, 1
            #   obj_pred 40, 40, 1
            #   obj_pred 20, 20, 1
            #---------------------------------------------------#
            obj_output  = self.obj_preds[k](reg_feat)

            output      = torch.cat([reg_output, obj_output, cls_output], 1)
            outputs.append(output)
        return outputs


class YOLOPAFPN(nn.Module):
    def __init__(self, depth = 1.0, width = 1.0, in_features = ("dark3", "dark4", "dark5"), in_channels = [256, 512, 1024], depthwise = False, act = "silu"):
        super().__init__()
        Conv                = DWConv if depthwise else BaseConv
        self.backbone       = CSPDarknet(depth, width, depthwise = depthwise, act = act)
        self.in_features    = in_features

        self.upsample       = nn.Upsample(scale_factor=2, mode="nearest")
        #-------------------------------------------#
        #   20, 20, 1024 -> 20, 20, 512
        #-------------------------------------------#
        self.lateral_conv0  = BaseConv(int(in_channels[2] * width), int(in_channels[1] * width), 1, 1, act=act)

        #-------------------------------------------#
        #   40, 40, 1024 -> 40, 40, 512
        #-------------------------------------------#
        self.C3_p4 = CSPLayer_neck(
            int(2 * in_channels[1] * width),
            int(in_channels[1] * width),
            round(3 * depth),
            False,
            depthwise = depthwise,
            act = act,
        )
        #-------------------------------------------#
        #   40, 40, 512 -> 40, 40, 256
        #-------------------------------------------#
        self.reduce_conv1   = BaseConv(int(in_channels[1] * width), int(in_channels[0] * width), 1, 1, act=act)
        #-------------------------------------------#
        #   80, 80, 512 -> 80, 80, 256
        #-------------------------------------------#
        self.C3_p3 = CSPLayer_neck(
            int(2 * in_channels[0] * width),
            int(in_channels[0] * width),
            round(3 * depth),
            False,
            depthwise = depthwise,
            act = act,
        )
        #-------------------------------------------#
        #   80, 80, 256 -> 40, 40, 256
        #-------------------------------------------#
        self.bu_conv2       = Conv(int(in_channels[0] * width), int(in_channels[0] * width), 3, 2, act=act)
        # self.spd_bu_conv2     = Spd(int(in_channels[0] * width))
        #-------------------------------------------#
        #   40, 40, 256 -> 40, 40, 512
        #-------------------------------------------#
        self.C3_n3 = CSPLayer_neck(
            int(2 * in_channels[0] * width),
            int(in_channels[1] * width),
            round(3 * depth),
            False,
            depthwise = depthwise,
            act = act,
        )
        #-------------------------------------------#
        #   40, 40, 512 -> 20, 20, 512
        #-------------------------------------------#
        self.bu_conv1       = Conv(int(in_channels[1] * width), int(in_channels[1] * width), 3, 2, act=act)
        # self.spd_bu_conv1     = Spd(int(in_channels[1] * width))
        #-------------------------------------------#
        #   20, 20, 1024 -> 20, 20, 1024
        #-------------------------------------------#
        self.C3_n4 = CSPLayer_neck(
            int(2 * in_channels[1] * width),
            int(in_channels[2] * width),

        )

        # self.evc = EVCBlock(int(in_channels[0] * width), int(in_channels[0] * width))
        # self.asff_512 = ASFF(0)
        # self.asff_256 = ASFF(1)
        # self.asff_128 = ASFF(2)

        # self.carafe_P5 = CARAFE(in_channels[0])
        # self.carafe_c3p4 = CARAFE(int(in_channels[0] * width))
        # self.mp2_behind_c3p3 = MP_2(int(in_channels[0] * width))
        # self.mp2_behind_c3n3 = MP_2(in_channels[0])
        # 3特征concat后通道数变为512 再降维到256 输入CSP融合
        # self.c3n3_dark4_reduce_conv = BaseConv(in_channels[1], in_channels[0], 1, 1, act=act)
        # self.c3n4_dark5_reduce_conv = BaseConv(in_channels[2], in_channels[1], 1, 1, act=act)

        # self.aff_concat_c3p4 = AFF_concat(in_channels[0])
        # self.aff_concat_c3p3 = AFF_concat(int(in_channels[0] * width))
        # self.aff_concat_c3n3 = AFF_concat(int(in_channels[0] * width))
        # self.aff_concat_c3n4 = AFF_concat(in_channels[0])
        # self.rfb_p3 = BasicRFB(int(in_channels[0] * width), int(in_channels[0] * width))
        # self.rfb_p4 = BasicRFB(in_channels[0], in_channels[0])
        # self.rfb_p5 = BasicRFB(in_channels[1], in_channels[1])
        # self.simam_P5 = simam_module(in_channels[1])
        # self.simam_P4 = simam_module(in_channels[0])
        # self.simam_P3 = simam_module(int(in_channels[0] * width))

    def forward(self, input):
        out_features            = self.backbone.forward(input)
        [feat1, feat2, feat3]   = [out_features[f] for f in self.in_features]
        # dark4的输出降维到128
        # feat2_128 = self.dark4_reduce_conv(feat2)
        #-------------------------------------------#
        #   20, 20, 1024 -> 20, 20, 512
        #-------------------------------------------#
        # feat3 = self.simam_P5(feat3)
        # feat2 = self.simam_P4(feat2)
        # feat1 = self.simam_P3(feat1)

        P5          = self.lateral_conv0(feat3)
        # P5          = self.evc(P5)
        #-------------------------------------------#
        #  20, 20, 512 -> 40, 40, 512
        #-------------------------------------------#
        P5_upsample = self.upsample(P5)
        # P5_upsample = self.carafe_P5(P5)
        #-------------------------------------------#
        #  40, 40, 512 + 40, 40, 512 -> 40, 40, 1024
        #-------------------------------------------#
        P5_upsample = torch.cat([P5_upsample, feat2], 1)
        # P5_upsample = self.aff_concat_c3p4(P5_upsample,feat2)
        #-------------------------------------------#
        #   40, 40, 1024 -> 40, 40, 512
        #-------------------------------------------#
        P5_upsample = self.C3_p4(P5_upsample)
        #-------------------------------------------#
        #   40, 40, 512 -> 40, 40, 256
        #-------------------------------------------#
        P4          = self.reduce_conv1(P5_upsample)
        #-------------------------------------------#
        #   40, 40, 256 -> 80, 80, 256
        #-------------------------------------------#
        P4_upsample = self.upsample(P4)
        # P4_upsample = self.carafe_c3p4(P4)
        #-------------------------------------------#
        #   80, 80, 256 + 80, 80, 256 -> 80, 80, 512
        #-------------------------------------------#
        P4_upsample = torch.cat([P4_upsample, feat1], 1)
        # P4_upsample = self.aff_concat_c3p3(P4_upsample, feat1)
        #-------------------------------------------#
        #   80, 80, 512 -> 80, 80, 256
        #-------------------------------------------#
        P3_out      = self.C3_p3(P4_upsample)
        # P3_out      = self.evc(P3_out)
        #-------------------------------------------#
        #   80, 80, 256 -> 40, 40, 256
        #-------------------------------------------#
        P3_downsample   = self.bu_conv2(P3_out)
        # P3_downsample     = self.spd_bu_conv2(P3_out)
        # P3_downsample   = self.mp2_behind_c3p3(P3_out)
        #-------------------------------------------#
        #   40, 40, 256 + 40, 40, 256 -> 40, 40, 512
        #-------------------------------------------#
        P3_downsample   = torch.cat([P3_downsample, P4], 1)
        # P3_downsample = self.aff_concat_c3n3(P3_downsample, P4)
        # P3_downsample   = self.c3n3_dark4_reduce_conv(P3_downsample)
        #-------------------------------------------#
        #   40, 40, 256 -> 40, 40, 512
        #-------------------------------------------#
        P4_out          = self.C3_n3(P3_downsample)
        #-------------------------------------------#
        #   40, 40, 512 -> 20, 20, 512
        #-------------------------------------------#
        P4_downsample   = self.bu_conv1(P4_out)
        # P4_downsample     = self.spd_bu_conv1(P4_out)
        # P4_downsample   = self.mp2_behind_c3n3(P4_out)
        #-------------------------------------------#
        #   20, 20, 512 + 20, 20, 512 -> 20, 20, 1024
        #-------------------------------------------#
        P4_downsample   = torch.cat([P4_downsample, P5], 1)
        # P4_downsample = self.aff_concat_c3n4(P4_downsample, P5)
        # P4_downsample   = self.c3n4_dark5_reduce_conv(P4_downsample)
        #-------------------------------------------#
        #   20, 20, 1024 -> 20, 20, 1024
        #-------------------------------------------#
        P5_out          = self.C3_n4(P4_downsample)
        #
        # P5_out          = self.asff_512(P5_out, P4_out, P3_out)
        # P4_out          = self.asff_256(P5_out, P4_out, P3_out)
        # P3_out          = self.asff_128(P5_out, P4_out, P3_out)

        # P3_out = self.rfb_p3(P3_out)
        # P4_out = self.rfb_p4(P4_out)
        # P5_out = self.rfb_p5(P5_out)

        return (P3_out, P4_out, P5_out)


class YoloBody(nn.Module):
    def __init__(self, num_classes, phi):
        super().__init__()
        depth_dict = {'nano': 0.33, 'tiny': 0.33, 's' : 0.33, 'm' : 0.67, 'l' : 1.00, 'x' : 1.33,}
        width_dict = {'nano': 0.25, 'tiny': 0.375, 's' : 0.50, 'm' : 0.75, 'l' : 1.00, 'x' : 1.25,}
        depth, width    = depth_dict[phi], width_dict[phi]
        depthwise       = True if phi == 'nano' else False

        self.backbone   = YOLOPAFPN(depth, width, depthwise=depthwise)
        self.head       = YOLOXHead(num_classes, width, depthwise=depthwise)

    def forward(self, x):
        fpn_outs    = self.backbone.forward(x)
        outputs     = self.head.forward(fpn_outs)
        return outputs
